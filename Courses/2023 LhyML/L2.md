## Framework of ML

- Training Data
- Function Set with unknown parameters
- Goodness of Fit
- Optimization
- Test Data
- Prediction

![alt text](image-2.png)

## Training Loss is large

### Model Bias

所有模型的集合的性能都非常差，表示模型的设计太简单了

### Optimization Issue

![alt text](image-3.png)

from Residual Network, the deep model can not be trained well

## Training Loss is Small but Test Loss is Large

更加有弹性的、复杂的模型，可以在训练集上表现的非常好，但是在测试集上表现的非常差

Solution：

1. 增加更多的训练资料
2. Data Augmentation（需要合理的增强）
3. Constraint the model to be simple
   1. Less parameters
   2. Sharing parameters(CNN)
   3. Early stopping
   4. Regularization
   5. Dropout

但是我们需要在训练集上表现的好，同时在测试集上表现的好，我们需要进行权衡

### Mismatch

分布发生了变化，训练集和测试集的分布不一样

## Optimization Issue

### Local Minima, Saddle Point

GD 只能找到梯度为 0 的点，但是这个点不一定是最优点，甚至不是局部最优点

可能为鞍点，我们可以通过泰勒展开来判断

$$
L(x) = L(x_0) + \nabla L(x_0)^T(x-x_0) + \frac{1}{2}(x-x_0)^T\nabla^2L(x_0)(x-x_0)
$$

使用 GD，在训练过程中卡在 Local Minima 的概率非常小，但是卡在 Saddle Point 的概率非常大

因此我们需要使用更加复杂的优化方法，比如 SGD、Momentum、Adam 等

## Batch

小批次和大批次

- `batch_size=1`：每次只更新一个样本
- `batch_size=n`：每次更新 n 个样本
- `batch_size=All`：每次更新所有样本，计算所有样本的平均梯度

更大的批次有时候一个批次并不需要更多的时间，因为我们可以使用并行计算，不过可能因为瓶颈问题，导致计算时间变长

但是一个 epoch，大的批次可能会更快，因为我们可以更快的计算梯度

但是小的批次会带来噪声，提供泛化性能，准确率更高

更神奇的是，同样性能的情况下，**小批次的模型在测试集上的性能比大批次的模型要好**

## Momentum

为梯度增加一个额外的惯性项，使得梯度更新更加平滑

- Vanilla GD

$$
\theta_{t+1} \gets \theta_t - \alpha g_t
$$

- GD + Momentum

从初始开始，参数为$\theta_0$，动量为$m_0=0$，计算梯度$g_t$，更新参数和动量

$$
m_{t+1} \gets \beta m_t + (1-\beta)g_t \\
\theta_{t+1} \gets \theta_t - \alpha m_{t+1}
$$

## Training Stuck != Small Gradient

![img](https://img2023.cnblogs.com/blog/3436855/202408/3436855-20240806212403141-589326622.png)

有可能是因为学习率太大，导致无法收敛

并且 training 如果是一个**凸优化**，固定学习率的梯度下降也不见得能够收敛

![img](https://img2023.cnblogs.com/blog/3436855/202408/3436855-20240806212937752-1960200220.png)

自适应调整学习率的方法，大的原则就是**梯度大的时候学习率小，梯度小的时候学习率大**

原始方法：

$$
\theta^{t+1}_i \gets \theta_t - \eta g^t_i \\
g^t_i = \nabla L(\theta_t)_i
$$

现在我们改写为：

$$
\theta^{t+1}_i \gets \theta^t_i - \frac{\eta}{\sigma^t_i} g^t_i \\
$$

### AdaGrad

$$
\sigma^0_i = | g^0_i | \\
\sigma^t_1 = \sqrt{\frac{1}{2} [(g^0_i)^2 + (g^1_i)^2]} \\
\cdots \\
\sigma^t_i = \sqrt{\frac{1}{t+1} \sum_{k=0}^t (g^k_i)^2}
$$

为什么这样自适应调整学习率是合理的呢？

因为我们希望梯度大的时候学习率小，梯度小的时候学习率大，所以我们希望学习率和梯度成反比

### RMSProp

我们希望 LR 的更新也是动态的，而不是一个 L2-norm 的累加，是一个指数加权平均

$$
\sigma^t_0 = \sqrt{(g^0_i)^2} \\
\sigma^t_i = \sqrt{\beta (\sigma^{t-1}_i)^2 + (1-\beta)(g^t_i)^2}
$$

### Adam: RMSProp + Momentum

### Learning Rate Scheduling

将学习率$\eta$也看做一个关于时间的函数

**- Learning Rate Decay**
as the number of iterations increases, the learning rate decreases

**- Warm Up**

- 一开始学习率比较小，然后逐渐增大，随后逐渐减小
