## ItemCF

项协同过滤

基本思想：如果用户喜欢物品 A，那么他可能也喜欢和物品 A 相似的物品 B, 即使用用户重叠来计算物品之间的相似度

将每一个物品表示为一个用户评分的稀疏向量，用户对物品的评分表示用户对物品的兴趣。

关键在于计算物品之间的相似性，根据我们的假设，相似度可以通过物品向量之间的 cosine similarity 来计算。

ItemCF 的计算如下：

用户对物品的兴趣： $\text{like}(\text{user}, \text{item}_j)$

物品之间的相似度： $\text{sim}(\text{item}_j, \text{item})$

用户对物品的兴趣： $\text{like}(\text{user}, \text{item}) = \sum_{\text{item}_j \in \text{items}} \text{like}(\text{user}, \text{item}_j) \times \text{sim}(\text{item}_j, \text{item})$

### 物品相似度计算

两个物品受众重合度越高，相似度越高

$\text{sim}(\text{item}_j, \text{item}) = \frac{|\text{users}(\text{item}_j) \cap \text{users}(\text{item})|}{\sqrt{|\text{users}(\text{item}_j)| \times |\text{users}(\text{item})|}}$

考虑用户对物品的评分，可以加权

$\text{sim}(\text{item}_j, \text{item}) = \frac{\sum_{\text{user} \in \text{users}(\text{item}_j) \cap \text{users}(\text{item})} (\text{like}(\text{user}, \text{item}_j) \times \text{like}(\text{user}, \text{item}))}{\sqrt{\sum_{\text{user} \in \text{users}(\text{item}_j)} \text{like}(\text{user}, \text{item}_j)^2 \times \sum_{\text{user} \in \text{users}(\text{item})} \text{like}(\text{user}, \text{item})^2}}$

实际上就是两个物品用户评分的余弦相似度

### 召回的完整流程

1. 事先做离线计算

   建立 用户-物品 索引

   建立 物品-物品 索引：计算物品之间的相似度，索引最相似的 TopK 个物品

2. 线上实时推荐

   1. 得出用户最近感兴趣的物品集合，lastN
   2. 从 lastN 中取出物品，找到与之相似的物品集合，TopK
   3. 对于取回的 nk 个物品，计算用户对物品的兴趣，排序，推荐给用户

   使用索引的意义在于避免遍历所有物品，提高效率，离线计算量大，线上实时推荐效率高

## Swing - ItemCF Variant

ItemCF 的不足之处在于，如果用户处于**一个小圈子**，本来没有交集的物品，会由于圈子的影响（分享在了同一个微信群），被推荐给用户

- 用户$u_1$喜欢的物品记作集合$J_1$
- 用户$u_2$喜欢的物品记作集合$J_2$
- 定义两个用户的重合度：$\text{overlap}(u_1,u_2) = |J_1 \cap J_2|$
- 如果两个用户的重合度很高，那么他们和可能来自于同一个小圈子，需要降低他们的权重

- 喜欢物品$i_1$的用户集合记作$W_1$
- 喜欢物品$i_2$的用户集合记作$W_2$
- 物品$i_1$和$i_2$的相似度：$\text{sim}(i_1, i_2) = \sum_{u_1 \in W_1} \sum_{u_2 \in W_2} \frac{1}{\alpha + \text{overlap}(u_1, u_2)}$

## UserCF

在用户中，有很多兴趣相似的用户，依照用户的兴趣，推荐给用户

根据用户-用户的相似度以及用户对物品的兴趣，计算用户对物品的兴趣

$\text{like}(\text{user}, \text{item}) = \sum_{\text{user}_j \in \text{users}} \text{sim}(\text{user}, \text{user}_j) \times \text{like}(\text{user}_j, \text{item})$

### 用户相似度

- 用户$u_1$喜欢的物品记作集合$J_1$
- 用户$u_2$喜欢的物品记作集合$J_2$

$\text{sim}(u_1, u_2) = \frac{|J_1 \cap J_2|}{\sqrt{|J_1| \times |J_2|}}$

但是，这样的计算方法等同对待热门和冷门物品，热门物品的相似度会被高估，因此需要对用户相似度进行修正

$$
\text{sim}(u_1, u_2) = \frac{\sum_{l \in | J_1 \cap J_2} \frac{1}{\log(1 + n_l)}}{\sqrt{|J_1| \times |J_2|}}
$$

### 召回的完整流程

1. 事先做离线计算

   建立 用户-物品 索引

   建立 用户-用户 索引：计算用户之间的相似度，索引最相似的 TopK 个用户

2. 线上实时推荐
   从用户-用户索引中取出与用户相似的 TopK 个用户
   从这些用户喜欢的物品中，取出 lastN 个物品
   对于取回的 nk 个物品，计算用户对物品的兴趣，排序，推荐给用户

## Matrix Completion

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604173916371-1101850206.png)

可以使用 Embedding 做推荐

- 用户的 embedding：$U \in \mathbb{R}^{k \times n}$
- 物品的 embedding：$V \in \mathbb{R}^{k \times m}$
- 内积表示用户对物品的兴趣：$R = U^T \times V$
- 数据集：（用户 ID， 物品 ID，兴趣分数），$\Omega = \{ i, j, r_ij \}$

那么就要求解最优化问题：

$$
\min_{U, V} \sum_{(i, j, r_{ij}) \in \Omega} (r_{ij} - u_i^T v_j)^2
$$

可以使用 SGD 算法求解

为什么叫 Matrix Completion 呢？因为我们只知道部分数据，需要填充矩阵的空缺

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604174514675-1976183972.png)

但是效果并不好

缺点 1：因为只考虑到了用户和物品的交互，没有考虑到用户与物品的具体属性

缺点 2：负样本的选取方式不对

缺点 3：损失函数、相似度计算方式不对

### 上线服务

1. 模型存储

   保存 U 和 V，但是往往 U 和 V 都很大，使用矩阵不便于实时添加与读入内存计算

   因此需要用 key-value 存储，key 为用户 ID，value 为用户的 embedding

   而 V 会更麻烦

2. 实时推荐

   1. 根据用户 ID，找到用户的 embedding
   2. 最近邻搜索，找到与用户最感兴趣的 k 个物品，这样的算法时间复杂度正比于笔记的数量

那么如何加速 ANN Search 呢？

### ANN Search

衡量最近邻的 Metric

- L1 距离
- L2 距离
- Cosine Similarity
- Inner Product

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604175345587-75888470.png)

根据 Metric，将数据集划分为不同类型的区域（cos 根据角度划分），然后在区域内搜索

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604175608124-1878842360.png)

很直观

## 双塔模型

对特征进行预处理，Embedding，归一化...

然后将所有特征输入到两个神经网络中，一个是用户的神经网络，一个是物品的神经网络，两个层的输出进行余弦相似度，得到用户对物品的兴趣

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604181210112-2021173161.png)

### 训练方法

#### **正负样本的选择**

- 正样本：用户点击的物品
- 负样本
  - 没有被召回的？
  - 召回但是被粗排、精排淘汰的？
  - 曝光但没有被点击的物品？

**正样本**

问题：少部分物品占据大部分点击，导致正样本都是热门物品(存疑，有什么问题吗？)

一种可能的解释是，输入的是一个正负样本对，但是这个正样本会被多个负样本与用户共享，导致正样本的权重过大

解决方法：up-sampling, down-sampling

**全体物品**（属于简单负样本）

只挑选没有被召回的物品，需要进行抽样

为了打压热门物品，可以使用负采样，即按照物品的点击率进行采样

$P \propto \text{click num}^{0.75}$

**Batch 内负样本**(也属于简单负样本)

利用 对比学习 的思想，每个 Batch 内的负样本是 Batch 内的其他正样本

问题： 热门物品成为负样本的概率过大了，因为出现在负样本的概率正比于点击次数

解决方法：物品 i 被抽样到的概率$p_i \propto \text{click num}$，我们调整用户对物品 i 的兴趣$\cos (a,b_i) - \log p_i$

**困难负样本**

- 被粗排淘汰的物品（与正样本相似，但是不是）
- 精排中排名靠后的物品（非常困难）

**工业常用的数据**

- 混合几种负样本

**选择负样本的原理**

召回的目标：快速找到用户可能感兴趣的物品，不是区分感兴趣和非常感兴趣的物品

- 简单负样本（easy）：用户根本不感兴趣
- 困难负样本（hard）：用户可能感兴趣，但是不够感兴趣
- 有曝光但是没有点击：用户可能感兴趣，但是可能碰巧没有点击

> 召回模型是负样本的艺术，排序模型是特征的艺术

#### 损失函数

- Pointwise：看作分类任务，正样本为 1，负样本为 -1
- Pairwise：看作排序任务，正样本的得分高于负样本
  - 如果$\cos (a,b^+) > \cos (a, b^-) + m$,则损失为 0
  - 否则，损失为$\cos (a,b^-) - \cos (a, b^+) + m$
  - 所以，Pairwise 的损失函数是 Hinge Loss, $L(a,b^+,b^-) = \max(0, \cos (a,b^-) - \cos (a, b^+) + m)$
- Listwise：看作排序任务，有单个正样本，多个负样本，使用交叉熵损失函数

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604184657645-2107167864.png)

### 一种不适用于召回的模型

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604184908395-1193052461.png)

在**前期就融合**了，效率非常低！因为不会产生中间的 Embedding，没有办法是用 ANN Search

### 线上服务

- 物品的 embedding

  使用 key-value 存储，key 为物品 ID，value 为物品的 embedding

  每做一次召回，都要使用到 billions 级别的物品，因此需要使用分布式存储

  同时物品特征相对稳定

- 用户的 embedding

  直接上线计算，因为用户的兴趣要实时变化，离线存储计算成本太高

### 模型更新

1. 全量更新

   - 在昨天的模型参数上，重新训练，然后替换
   - 使用昨天的数据，训练一个 epoch
   - 发布新的用户塔神经网络和物品向量
   - 对数据流与系统的要求比较低

2. 增量更新（online learning 更新模型参数）

   - 用户兴趣的变化是连续的，因此可以使用增量更新
   - 实时收集线上数据，做流式处理
   - 对模型做 online learning，每次只更新一部分参数（embedding 层，不更新 fc 层）
   - 发布 用户 ID embedding

既要做**全量更新**，又要做**增量更新**

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604191632394-1295474281.png)

只做增量：用户在每一个时间刻度的 embedding 是不一样的，因此需要全量更新

### 自监督学习

batch 内负样本，双塔模型的损失函数为

$$
L_i = \frac{\exp(\cos (a_i, b_i) - \log p_i)}{\sum_{j=1}^N \exp(\cos (a_i, b_j) - \log p_j)}
$$

要做梯度下降，减小损失函数

$$
L = \sum_{i=1}^N L_i
$$

---

使用自监督学习，**让不同物品的 embedding 之间的余弦相似度尽可能小，让相似物品的 embedding 之间的余弦相似度尽可能大**

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240604212910550-884240994.png)

特征变换：Random Mask

- 随机选择一些离散特征，把他们变成 0

特征变换：Dropout

- 随机丢弃离散特征中 50%的值

特征变换：互补特征

因此，最终训练的时候就会有两个损失函数，一个是原来的对比学习，一个是自监督学习

## Deep Retrieval

根据用户对物品路径的兴趣，推荐给用户

### 索引

索引将物品与路径关联起来

- 将物品表征为路径

  ![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240605185639717-782376068.png)

- 物品到路径的索引：item -> List[path]
- 路径到物品的索引：path -> List[item]

### 预估模型

预估用户对路径的兴趣分数$p([a,b,c] | x)$

$$
p([a,b,c] | x) = p(a | x) \times p(b | x, a) \times p(c | x, a, b)
$$

我们可以使用三个神经网络来预估这三个概率

![img](https://img2023.cnblogs.com/blog/3436855/202406/3436855-20240605190307738-1052184299.png)

### 召回模型

召回：用户->路径->物品

- 第一步：使用 beam search 在这样的序列模型中找到最可能的 K 条路径
- 第二步：使用 path->item 的索引，找到路径对应的物品

### 线上召回

给定用户的 embedding，找到最可能的路径，然后找到路径对应的物品，使用一个小的排序模型，返回给定的物品数目

### 训练

如果用户点击了物品，那么路径上全为这个物品的路径的概率应该很高
